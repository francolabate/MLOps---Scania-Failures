{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a3883080-cf6b-4f7d-9e1d-a3f3d2bc9703",
    "_uuid": "2be61f7cd45859c44c18fe9688aebbd5c83c1412"
   },
   "source": [
    "The data and the description:\n",
    "https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks\n",
    "\n",
    "Abstract: The datasets' positive class consists of component failures for a specific component of the APS system. The negative class consists of trucks with failures for components not related to the APS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (2.13.1)\n",
      "Requirement already satisfied: tensorflow in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (2.13.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.22.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.24.2)\n",
      "Requirement already satisfied: packaging in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.33.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: setuptools in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.57.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/murnis/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import requests as req\n",
    "from io import BytesIO\n",
    "import boto3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import predictions as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-east-1'\n",
    "BUCKET_NAME = 'mma-models-in-production' # Unique through all accounts\n",
    "FOLDER = 'dist' # Should be clean before the execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>76698</td>\n",
       "      <td>0</td>\n",
       "      <td>2130706438</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>33058</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>41040</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>60874</td>\n",
       "      <td>0</td>\n",
       "      <td>1368</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>neg</td>\n",
       "      <td>153002</td>\n",
       "      <td>0</td>\n",
       "      <td>664</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>neg</td>\n",
       "      <td>2286</td>\n",
       "      <td>0</td>\n",
       "      <td>2130706538</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>neg</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>2130706432</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>neg</td>\n",
       "      <td>80292</td>\n",
       "      <td>0</td>\n",
       "      <td>2130706432</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>neg</td>\n",
       "      <td>40222</td>\n",
       "      <td>0</td>\n",
       "      <td>698</td>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class  aa_000 ab_000      ac_000 ad_000 eg_000\n",
       "0       neg   76698      0  2130706438    280      0\n",
       "1       neg   33058      0           0      0      0\n",
       "2       neg   41040      0         228    100      0\n",
       "3       neg      12      0          70     66     32\n",
       "4       neg   60874      0        1368    458      0\n",
       "...     ...     ...    ...         ...    ...    ...\n",
       "59995   neg  153002      0         664    186      0\n",
       "59996   neg    2286      0  2130706538    224      0\n",
       "59997   neg     112      0  2130706432     18      0\n",
       "59998   neg   80292      0  2130706432    494      0\n",
       "59999   neg   40222      0         698    628      0\n",
       "\n",
       "[60000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv('data/aps_failure_training_set.csv', dtype = 'str')\n",
    "df_original = df_original.replace(r'na', 0, regex=True)\n",
    "df_original = df_original.drop(df_original.iloc[:, 5:-1],axis = 1)\n",
    "df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint, uniform\n",
    "\n",
    "df_original['aa_000'] = df_original['aa_000'].astype(float)\n",
    "df_original['ab_000'] = df_original['ab_000'].astype(float)\n",
    "df_original['ac_000'] = df_original['ac_000'].astype(float)\n",
    "df_original['ad_000'] = df_original['ad_000'].astype(float)\n",
    "df_original['eg_000'] = df_original['eg_000'].astype(int)\n",
    "\n",
    "aa_000 = uniform(0,df_original['aa_000'].max())\n",
    "ab_000 = uniform(0,df_original['ab_000'].max())\n",
    "ac_000 = uniform(0,df_original['ac_000'].max())\n",
    "ad_000 = uniform(0,df_original['ad_000'].max())\n",
    "eg_000 = uniform(0,df_original['eg_000'].max())\n",
    "sample = [aa_000, ab_000, ac_000, ad_000, eg_000]\n",
    "np.array(sample).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2746564"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original['aa_000'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_normalizer(input_data: pd.DataFrame) -> StandardScaler:\n",
    "    \"\"\"\n",
    "        Fit a scikit-learn Normalizer based on input_data.\n",
    "    \"\"\"    \n",
    "    scaler = StandardScaler()\n",
    "    print('Fitting a Normalizer with given input')    \n",
    "    scaler.fit(input_data)\n",
    "    \n",
    "    file_name = 'normalizer.pkl'\n",
    "    with open(os.path.join(FOLDER, file_name), 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    # TODO Part 2\n",
    "    # au.upload_to_s3(BUCKET_NAME, FOLDER, file_name)        \n",
    "    \n",
    "    print('Normalizer saved')\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Normalizer with given input\n",
      "Normalizer saved\n"
     ]
    }
   ],
   "source": [
    "normalizer = fit_normalizer(df_original.drop(\"class\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = normalizer.transform(df_original.drop(\"class\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_encoder(target_list: list) -> LabelEncoder:\n",
    "    \"\"\"\n",
    "        Fit a scikit-learn LabelEncoder based on target_list.\n",
    "    \"\"\"    \n",
    "    encoder = LabelEncoder()\n",
    "    print('Fitting a LabelEncoder with given target')\n",
    "    encoder.fit(target_list)\n",
    "    \n",
    "    print('Found classes', encoder.classes_)\n",
    "    print('Testing encoder', encoder.transform(encoder.classes_))\n",
    "    \n",
    "    file_name = 'encoder.pkl'\n",
    "    with open(os.path.join(FOLDER, file_name), 'wb') as f:\n",
    "        pickle.dump(encoder, f)\n",
    "\n",
    "    # TODO Part 2        \n",
    "    # au.upload_to_s3(BUCKET_NAME, FOLDER, file_name)        \n",
    "    \n",
    "    print('Encoder saved')\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a LabelEncoder with given target\n",
      "Found classes ['neg' 'pos']\n",
      "Testing encoder [0 1]\n",
      "Encoder saved\n"
     ]
    }
   ],
   "source": [
    "# All the target column\n",
    "target_list = df_original['class'].tolist()\n",
    "encoder = fit_encoder(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_and_one_hot_target(target_list: list, encoder: LabelEncoder) -> np.ndarray:\n",
    "    print('Encoding target with given encoder')\n",
    "    targets_encoded = encoder.transform(target_list)\n",
    "    \n",
    "    print('Target final shape', targets_encoded.shape)\n",
    "    return targets_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding target with given encoder\n",
      "Target final shape (60000,)\n"
     ]
    }
   ],
   "source": [
    "Y = encode_and_one_hot_target(target_list, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set is very unbalanced with one label (0) being more frequent than the other (1). The algorithm needs to adjust for that. \n",
    "It is done using 'class_weight' hyperparameter which is the ratio of number of 0s to 1s in the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_tr, X_t, Y_tr, Y_t = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_lr(X_tr: np.ndarray, Y_tr: np.ndarray) -> LogisticRegression:\n",
    "    \"\"\"\n",
    "        Fits a LR model, saves the model weights and returns it.\n",
    "    \"\"\"\n",
    "    weight = sum(Y_tr == 0)/sum(Y_tr == 1)\n",
    "    \n",
    "    # Instantiate the model learning model\n",
    "    lr_full = LogisticRegression(C = 1, class_weight={1:weight}, random_state = 0)\n",
    "    \n",
    "    # Fitting the model\n",
    "    print('Fitting model')\n",
    "    model = lr_full.fit(X_tr, Y_tr)\n",
    "    \n",
    "    file_name = 'model.pkl'\n",
    "    with open(os.path.join(FOLDER, file_name), 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "      \n",
    "    # TODO Part 2    \n",
    "    # au.upload_to_s3(BUCKET_NAME, FOLDER, file_name)        \n",
    "\n",
    "    print('Model saved')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "model = fit_lr(X_tr, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_pr = model.predict(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545833333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_t, Y_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21585"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the score using confusion matrix values\n",
    "def score(cm):\n",
    "    cm_score = cm[0][1] * 10 + cm[1][0] * 500\n",
    "    cm_score = int(cm_score * 1.33) #1.33 is because the actual test set is 33% larger than this test set\n",
    "    return cm_score\n",
    "#calculate confusion matrix\n",
    "cm = confusion_matrix(Y_t, Y_pr)\n",
    "score(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c8dc4c0-0fb6-499b-96ac-3eb73f64a3a2",
    "_uuid": "ab973b9ccda8ba3fd4649c22bb62c9c38cb07487"
   },
   "source": [
    "21585 is our basic score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.10",
   "language": "python",
   "name": "python-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
